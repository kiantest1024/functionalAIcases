#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå¢å¼ºåŠŸèƒ½æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ - Webç‰ˆæœ¬
ç»“åˆäººå·¥æ™ºèƒ½å’Œæ‰€æœ‰æµ‹è¯•è®¾è®¡æ–¹æ³•çš„Webåº”ç”¨
"""

from flask import Flask, render_template, request, jsonify, send_file, flash, redirect, url_for
import os
import json
import tempfile
import time
from datetime import datetime
import io
import zipfile
from ai_test_generator import AITestCaseGenerator
from comprehensive_test_generator import ComprehensiveTestGenerator
from ai_test_generator import AITestMethod, AIAnalysisResult
from real_ai_generator import RealAITestCaseGenerator, AIProvider, AIConfig
from ai_config_manager import config_manager

app = Flask(__name__)
app.secret_key = 'ai_test_case_generator_secret_key_2025'

# é…ç½®ä¸Šä¼ æ–‡ä»¶å¤¹
UPLOAD_FOLDER = 'uploads'
OUTPUT_FOLDER = 'outputs'
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['OUTPUT_FOLDER'] = OUTPUT_FOLDER

# ç¡®ä¿æ–‡ä»¶å¤¹å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

def create_ai_generator(custom_headers=None):
    """åˆ›å»ºAIç”Ÿæˆå™¨ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®AIï¼‰"""
    ai_config = config_manager.load_config()
    if ai_config and ai_config.api_key:
        try:
            return RealAITestCaseGenerator(ai_config, custom_headers)
        except Exception as e:
            print(f"åˆ›å»ºçœŸå®AIç”Ÿæˆå™¨å¤±è´¥ï¼Œé™çº§åˆ°æ¨¡æ‹ŸAI: {e}")

    # é™çº§åˆ°å…¨é¢æµ‹è¯•ç”Ÿæˆå™¨
    return ComprehensiveTestGenerator(custom_headers)

@app.route('/')
def index():
    """AIå¢å¼ºä¸»é¡µ"""
    return render_template('ai_index.html')

@app.route('/ai_generate', methods=['GET', 'POST'])
def ai_generate():
    """AIå¢å¼ºç”Ÿæˆæµ‹è¯•ç”¨ä¾‹é¡µé¢"""
    if request.method == 'GET':
        return render_template('ai_generate.html')
    
    try:
        # è·å–è¡¨å•æ•°æ®
        requirement_text = request.form.get('requirement_text', '').strip()
        historical_defects = request.form.get('historical_defects', '').strip()
        custom_headers = request.form.get('custom_headers', '').strip()
        ai_enhancement_level = request.form.get('ai_enhancement_level', 'medium')
        
        if not requirement_text:
            flash('è¯·è¾“å…¥éœ€æ±‚æ–‡æ¡£å†…å®¹', 'error')
            return redirect(url_for('ai_generate'))
        
        # å¤„ç†å†å²ç¼ºé™·
        defects_list = []
        if historical_defects:
            defects_list = [d.strip() for d in historical_defects.split('\n') if d.strip()]
        
        # å¤„ç†è‡ªå®šä¹‰å­—æ®µæ ‡é¢˜
        headers_dict = None
        if custom_headers:
            try:
                headers_dict = json.loads(custom_headers)
            except json.JSONDecodeError:
                flash('è‡ªå®šä¹‰å­—æ®µæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨æ­£ç¡®çš„JSONæ ¼å¼', 'error')
                return redirect(url_for('ai_generate'))
        
        # åˆ›å»ºAIå¢å¼ºç”Ÿæˆå™¨ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®AIï¼‰
        ai_generator = create_ai_generator(headers_dict)
        
        # AIåˆ†æéœ€æ±‚ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®AIï¼‰
        if hasattr(ai_generator, 'real_ai_analyze_requirements'):
            print("ğŸ¤– ä½¿ç”¨çœŸå®AIåˆ†æéœ€æ±‚...")
            ai_analysis = ai_generator.real_ai_analyze_requirements(requirement_text)
        else:
            print("ğŸ”§ ä½¿ç”¨æ¨¡æ‹ŸAIåˆ†æéœ€æ±‚...")
            ai_analysis = ai_generator.ai_analyze_requirements(requirement_text)
        
        # æ ¹æ®å¢å¼ºçº§åˆ«è°ƒæ•´ç”Ÿæˆç­–ç•¥
        if ai_enhancement_level == 'basic':
            # åŸºç¡€å¢å¼º - ä½¿ç”¨å…¨é¢æµ‹è¯•ç”Ÿæˆå™¨
            if hasattr(ai_generator, 'generate_comprehensive_test_cases'):
                test_cases = ai_generator.generate_comprehensive_test_cases(requirement_text, defects_list)
            else:
                test_cases = ai_generator.generate_all_test_cases(requirement_text, defects_list)
        elif ai_enhancement_level == 'advanced':
            # é«˜çº§AIå¢å¼º - ä½¿ç”¨çœŸå®AI
            if hasattr(ai_generator, 'generate_real_ai_enhanced_test_cases'):
                test_cases = ai_generator.generate_real_ai_enhanced_test_cases(requirement_text, defects_list)
            elif hasattr(ai_generator, 'generate_comprehensive_test_cases'):
                test_cases = ai_generator.generate_comprehensive_test_cases(requirement_text, defects_list)
            else:
                test_cases = ai_generator.generate_ai_enhanced_test_cases(requirement_text, defects_list)
        else:
            # ä¸­ç­‰AIå¢å¼ºï¼ˆé»˜è®¤ï¼‰
            if hasattr(ai_generator, 'generate_real_ai_enhanced_test_cases'):
                test_cases = ai_generator.generate_real_ai_enhanced_test_cases(requirement_text, defects_list)
            elif hasattr(ai_generator, 'generate_comprehensive_test_cases'):
                test_cases = ai_generator.generate_comprehensive_test_cases(requirement_text, defects_list)
            else:
                test_cases = ai_generator.generate_ai_enhanced_test_cases(requirement_text, defects_list)
        
        # ç”Ÿæˆæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Excelæ–‡ä»¶
        excel_filename = f"ai_test_cases_{timestamp}.xlsx"
        excel_path = os.path.join(app.config['OUTPUT_FOLDER'], excel_filename)

        print(f"ğŸ“Š å‡†å¤‡ç”ŸæˆExcelæ–‡ä»¶: {excel_filename}")
        print(f"ğŸ“ Excelæ–‡ä»¶è·¯å¾„: {excel_path}")

        try:
            ai_generator.export_to_excel(excel_path)
            if os.path.exists(excel_path):
                file_size = os.path.getsize(excel_path)
                print(f"âœ… Excelæ–‡ä»¶ç”ŸæˆæˆåŠŸ: {excel_path} ({file_size} bytes)")
            else:
                print(f"âŒ Excelæ–‡ä»¶ç”Ÿæˆå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {excel_path}")
        except Exception as e:
            print(f"âŒ Excelæ–‡ä»¶ç”Ÿæˆå¼‚å¸¸: {e}")

        # AIå¢å¼ºæŠ¥å‘Š
        ai_report_filename = f"ai_enhanced_report_{timestamp}.md"
        ai_report_path = os.path.join(app.config['OUTPUT_FOLDER'], ai_report_filename)

        print(f"ğŸ“ å‡†å¤‡ç”ŸæˆMarkdownæŠ¥å‘Š: {ai_report_filename}")
        print(f"ğŸ“ Markdownæ–‡ä»¶è·¯å¾„: {ai_report_path}")

        try:
            ai_generator.export_ai_enhanced_report(ai_report_path)
            if os.path.exists(ai_report_path):
                file_size = os.path.getsize(ai_report_path)
                print(f"âœ… MarkdownæŠ¥å‘Šç”ŸæˆæˆåŠŸ: {ai_report_path} ({file_size} bytes)")
            else:
                print(f"âŒ MarkdownæŠ¥å‘Šç”Ÿæˆå¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {ai_report_path}")
        except Exception as e:
            print(f"âŒ MarkdownæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        stats = generate_ai_statistics(test_cases, ai_analysis)
        
        return render_template('ai_result.html', 
                             test_cases=test_cases[:10],  # åªæ˜¾ç¤ºå‰10ä¸ª
                             ai_analysis=ai_analysis,
                             stats=stats,
                             excel_file=excel_filename,
                             ai_report_file=ai_report_filename,
                             total_cases=len(test_cases),
                             enhancement_level=ai_enhancement_level)
        
    except Exception as e:
        flash(f'AIç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}', 'error')
        return redirect(url_for('ai_generate'))

@app.route('/ai_analysis', methods=['POST'])
def ai_analysis():
    """AIéœ€æ±‚åˆ†ææ¥å£"""
    try:
        data = request.get_json()
        requirement_text = data.get('requirement_text', '')
        
        if not requirement_text:
            return jsonify({'error': 'éœ€æ±‚æ–‡æ¡£å†…å®¹ä¸èƒ½ä¸ºç©º'}), 400
        
        # åˆ›å»ºAIç”Ÿæˆå™¨å¹¶åˆ†æï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®AIï¼‰
        ai_generator = create_ai_generator()

        # ä½¿ç”¨çœŸå®AIåˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if hasattr(ai_generator, 'real_ai_analyze_requirements'):
            print("ğŸ¤– AIåˆ†ææ¥å£ä½¿ç”¨çœŸå®AI...")
            ai_analysis = ai_generator.real_ai_analyze_requirements(requirement_text)
        else:
            print("ğŸ”§ AIåˆ†ææ¥å£ä½¿ç”¨æ¨¡æ‹ŸAI...")
            ai_analysis = ai_generator.ai_analyze_requirements(requirement_text)
        
        # è½¬æ¢ä¸ºJSONæ ¼å¼
        analysis_data = {
            'complexity_score': ai_analysis.complexity_score,
            'complexity_level': get_complexity_level(ai_analysis.complexity_score),
            'risk_areas': ai_analysis.risk_areas,
            'critical_paths': ai_analysis.critical_paths,
            'data_patterns': ai_analysis.data_patterns,
            'business_rules': ai_analysis.business_rules,
            'integration_points': ai_analysis.integration_points,
            'performance_concerns': ai_analysis.performance_concerns,
            'security_risks': ai_analysis.security_risks,
            'usability_factors': ai_analysis.usability_factors
        }
        
        return jsonify({
            'success': True,
            'analysis': analysis_data,
            'recommendations': generate_ai_recommendations(ai_analysis)
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/ai_smart_template')
def ai_smart_template():
    """AIæ™ºèƒ½æ¨¡æ¿é¡µé¢"""
    # åŠ è½½é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡æ¿
    try:
        with open('test_config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        templates = config.get('sample_requirements', {})
    except:
        templates = {}
    
    return render_template('ai_smart_template.html', templates=templates)

@app.route('/ai_generate_from_smart_template', methods=['POST'])
def ai_generate_from_smart_template():
    """ä»AIæ™ºèƒ½æ¨¡æ¿ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
    try:
        template_name = request.form.get('template_name')
        ai_enhancement_options = request.form.getlist('ai_enhancement_options')
        custom_params = request.form.get('custom_params', '').strip()
        
        # åŠ è½½æ¨¡æ¿
        with open('test_config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        templates = config.get('sample_requirements', {})
        if template_name not in templates:
            flash('æ¨¡æ¿ä¸å­˜åœ¨', 'error')
            return redirect(url_for('ai_smart_template'))
        
        template = templates[template_name]
        requirement_text = template['content']
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if custom_params:
            try:
                params = json.loads(custom_params)
                for key, value in params.items():
                    requirement_text = requirement_text.replace(f"{{{key}}}", str(value))
            except json.JSONDecodeError:
                flash('è‡ªå®šä¹‰å‚æ•°æ ¼å¼é”™è¯¯', 'error')
                return redirect(url_for('ai_smart_template'))
        
        # åˆ›å»ºAIå¢å¼ºç”Ÿæˆå™¨ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®AIï¼‰
        ai_generator = create_ai_generator()
        
        # æ ¹æ®AIå¢å¼ºé€‰é¡¹è°ƒæ•´ç”Ÿæˆç­–ç•¥
        if 'deep_analysis' in ai_enhancement_options:
            # æ·±åº¦åˆ†ææ¨¡å¼ - ä½¿ç”¨çœŸå®AI
            if hasattr(ai_generator, 'real_ai_analyze_requirements'):
                print("ğŸ¤– æ™ºèƒ½æ¨¡æ¿ä½¿ç”¨çœŸå®AIæ·±åº¦åˆ†æ...")
                ai_analysis = ai_generator.real_ai_analyze_requirements(requirement_text)
                if hasattr(ai_generator, 'generate_real_ai_enhanced_test_cases'):
                    test_cases = ai_generator.generate_real_ai_enhanced_test_cases(requirement_text)
                else:
                    test_cases = ai_generator.generate_ai_enhanced_test_cases(requirement_text)
            else:
                print("ğŸ”§ æ™ºèƒ½æ¨¡æ¿ä½¿ç”¨æ¨¡æ‹ŸAIåˆ†æ...")
                ai_analysis = ai_generator.ai_analyze_requirements(requirement_text)
                test_cases = ai_generator.generate_ai_enhanced_test_cases(requirement_text)
        else:
            # æ ‡å‡†æ¨¡å¼ - ä½¿ç”¨å…¨é¢æµ‹è¯•ç”Ÿæˆå™¨
            if hasattr(ai_generator, 'generate_comprehensive_test_cases'):
                test_cases = ai_generator.generate_comprehensive_test_cases(requirement_text)
            else:
                test_cases = ai_generator.generate_all_test_cases(requirement_text)
            if hasattr(ai_generator, 'real_ai_analyze_requirements'):
                ai_analysis = ai_generator.real_ai_analyze_requirements(requirement_text)
            else:
                ai_analysis = ai_generator.ai_analyze_requirements(requirement_text)
        
        # åº”ç”¨AIå¢å¼ºé€‰é¡¹
        if 'risk_prioritization' in ai_enhancement_options:
            ai_generator._adjust_risk_based_priority(test_cases, ai_analysis)
        
        if 'coverage_optimization' in ai_enhancement_options:
            test_cases = ai_generator._optimize_coverage(test_cases, ai_analysis)
        
        # ç”Ÿæˆæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        excel_filename = f"ai_smart_template_{template_name}_{timestamp}.xlsx"
        excel_path = os.path.join(app.config['OUTPUT_FOLDER'], excel_filename)
        ai_generator.export_to_excel(excel_path)
        
        ai_report_filename = f"ai_smart_report_{template_name}_{timestamp}.md"
        ai_report_path = os.path.join(app.config['OUTPUT_FOLDER'], ai_report_filename)
        ai_generator.export_ai_enhanced_report(ai_report_path)
        
        flash(f'æˆåŠŸä»AIæ™ºèƒ½æ¨¡æ¿"{template["title"]}"ç”Ÿæˆäº†{len(test_cases)}ä¸ªæµ‹è¯•ç”¨ä¾‹', 'success')
        
        stats = generate_ai_statistics(test_cases, ai_analysis)
        
        return render_template('ai_smart_template_result.html',
                             template_title=template['title'],
                             test_cases=test_cases[:10],
                             ai_analysis=ai_analysis,
                             stats=stats,
                             total_cases=len(test_cases),
                             excel_file=excel_filename,
                             ai_report_file=ai_report_filename,
                             enhancement_options=ai_enhancement_options)
        
    except Exception as e:
        flash(f'ä»AIæ™ºèƒ½æ¨¡æ¿ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}', 'error')
        return redirect(url_for('ai_smart_template'))

@app.route('/download/<filename>')
def download_file(filename):
    """ä¸‹è½½æ–‡ä»¶"""
    try:
        file_path = os.path.join(app.config['OUTPUT_FOLDER'], filename)

        print(f"ğŸ” ä¸‹è½½è¯·æ±‚: {filename}")
        print(f"ğŸ“ å®Œæ•´è·¯å¾„: {file_path}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {app.config['OUTPUT_FOLDER']}")

        # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(file_path):
            print(f"âœ… æ–‡ä»¶å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½")
            # ä½¿ç”¨ç»å¯¹è·¯å¾„ç¡®ä¿Flaskèƒ½æ‰¾åˆ°æ–‡ä»¶
            abs_file_path = os.path.abspath(file_path)
            print(f"ğŸ“ ä½¿ç”¨ç»å¯¹è·¯å¾„: {abs_file_path}")

            # å†æ¬¡éªŒè¯ç»å¯¹è·¯å¾„æ–‡ä»¶å­˜åœ¨
            if os.path.exists(abs_file_path):
                try:
                    return send_file(abs_file_path, as_attachment=True)
                except Exception as e:
                    print(f"âŒ send_fileå¤±è´¥: {e}")
                    # å¦‚æœsend_fileå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨è¯»å–æ–‡ä»¶
                    try:
                        from flask import Response
                        with open(abs_file_path, 'rb') as f:
                            file_data = f.read()

                        response = Response(
                            file_data,
                            mimetype='application/octet-stream',
                            headers={
                                'Content-Disposition': f'attachment; filename={filename}',
                                'Content-Length': len(file_data)
                            }
                        )
                        print(f"âœ… ä½¿ç”¨æ‰‹åŠ¨è¯»å–æ–¹å¼ä¸‹è½½æ–‡ä»¶")
                        return response
                    except Exception as e2:
                        print(f"âŒ æ‰‹åŠ¨è¯»å–ä¹Ÿå¤±è´¥: {e2}")
            else:
                print(f"âŒ ç»å¯¹è·¯å¾„æ–‡ä»¶ä¸å­˜åœ¨: {abs_file_path}")

        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾ç±»ä¼¼çš„æ–‡ä»¶
        print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")

        # åˆ—å‡ºoutputsç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        output_dir = app.config['OUTPUT_FOLDER']
        if os.path.exists(output_dir):
            all_files = os.listdir(output_dir)
            print(f"ğŸ“„ ç›®å½•ä¸­çš„æ–‡ä»¶: {all_files}")
        else:
            print(f"âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {output_dir}")
            flash('è¾“å‡ºç›®å½•ä¸å­˜åœ¨', 'error')
            return redirect(url_for('index'))

        # æå–æ–‡ä»¶åæ¨¡å¼ï¼ˆå»æ‰æ—¶é—´æˆ³ï¼‰
        if filename.startswith('ai_test_cases_'):
            pattern = 'ai_test_cases_'
            extension = '.xlsx'
        elif filename.startswith('ai_enhanced_report_'):
            pattern = 'ai_enhanced_report_'
            extension = '.md'
        elif filename.startswith('ai_smart_template_'):
            pattern = 'ai_smart_template_'
            extension = '.xlsx'
        else:
            pattern = None
            extension = None

        print(f"ğŸ” æŸ¥æ‰¾æ¨¡å¼: {pattern}{extension}")

        # æŸ¥æ‰¾æœ€æ–°çš„åŒ¹é…æ–‡ä»¶
        if pattern and extension:
            matching_files = [f for f in all_files if f.startswith(pattern) and f.endswith(extension)]
            print(f"ğŸ“‹ åŒ¹é…çš„æ–‡ä»¶: {matching_files}")

            if matching_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
                latest_file = max(matching_files, key=lambda f: os.path.getmtime(os.path.join(output_dir, f)))
                latest_path = os.path.join(output_dir, latest_file)

                print(f"âœ… æ‰¾åˆ°æœ€æ–°æ–‡ä»¶: {latest_file}")
                print(f"ğŸ“ æœ€æ–°æ–‡ä»¶è·¯å¾„: {latest_path}")

                if os.path.exists(latest_path):
                    return send_file(latest_path, as_attachment=True)
                else:
                    print(f"âŒ æœ€æ–°æ–‡ä»¶ä¸å­˜åœ¨: {latest_path}")

        # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œè¿”å›é”™è¯¯
        print(f"âŒ æ— æ³•æ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶")
        flash(f'æ–‡ä»¶ä¸å­˜åœ¨: {filename}ã€‚è¯·é‡æ–°ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚', 'error')
        return redirect(url_for('ai_generate'))

    except Exception as e:
        print(f"âŒ ä¸‹è½½æ–‡ä»¶å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        flash(f'ä¸‹è½½æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}', 'error')
        return redirect(url_for('ai_generate'))

def generate_ai_statistics(test_cases, ai_analysis):
    """ç”ŸæˆAIç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'total_cases': len(test_cases),
        'complexity_score': ai_analysis.complexity_score,
        'complexity_level': get_complexity_level(ai_analysis.complexity_score),
        'priority_stats': {},
        'ai_method_stats': {},
        'risk_coverage': {},
        'enhancement_metrics': {}
    }
    
    # ä¼˜å…ˆçº§ç»Ÿè®¡
    for case in test_cases:
        priority = case.priority.value
        stats['priority_stats'][priority] = stats['priority_stats'].get(priority, 0) + 1
    
    # AIæ–¹æ³•ç»Ÿè®¡
    for case in test_cases:
        for ai_method in AITestMethod:
            if ai_method.value in case.remark:
                stats['ai_method_stats'][ai_method.value] = stats['ai_method_stats'].get(ai_method.value, 0) + 1
    
    # é£é™©è¦†ç›–ç»Ÿè®¡
    if ai_analysis.risk_areas:
        covered_risks = set()
        for case in test_cases:
            case_text = f"{case.module} {case.submodule} {case.test_steps} {case.remark}".lower()
            for risk in ai_analysis.risk_areas:
                if risk.lower() in case_text:
                    covered_risks.add(risk)
        
        stats['risk_coverage'] = {
            'total_risks': len(ai_analysis.risk_areas),
            'covered_risks': len(covered_risks),
            'coverage_rate': len(covered_risks) / len(ai_analysis.risk_areas) * 100 if ai_analysis.risk_areas else 0
        }
    
    # AIå¢å¼ºæŒ‡æ ‡
    ai_enhanced_cases = sum(1 for case in test_cases if any(ai_method.value in case.remark for ai_method in AITestMethod))
    stats['enhancement_metrics'] = {
        'ai_enhanced_cases': ai_enhanced_cases,
        'enhancement_rate': ai_enhanced_cases / len(test_cases) * 100 if test_cases else 0
    }
    
    return stats

def get_complexity_level(score):
    """è·å–å¤æ‚åº¦ç­‰çº§"""
    if score > 0.7:
        return "é«˜"
    elif score > 0.4:
        return "ä¸­"
    else:
        return "ä½"

def generate_ai_recommendations(ai_analysis):
    """ç”ŸæˆAIå»ºè®®"""
    recommendations = []
    
    if ai_analysis.complexity_score > 0.8:
        recommendations.append("ç³»ç»Ÿå¤æ‚åº¦è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ é›†æˆæµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•")
    
    if len(ai_analysis.security_risks) > 3:
        recommendations.append("æ£€æµ‹åˆ°å¤šä¸ªå®‰å…¨é£é™©ï¼Œå»ºè®®è¿›è¡Œä¸“é¡¹å®‰å…¨æµ‹è¯•")
    
    if len(ai_analysis.performance_concerns) > 2:
        recommendations.append("å­˜åœ¨å¤šä¸ªæ€§èƒ½å…³æ³¨ç‚¹ï¼Œå»ºè®®è¿›è¡Œæ€§èƒ½å‹åŠ›æµ‹è¯•")
    
    if len(ai_analysis.integration_points) > 5:
        recommendations.append("é›†æˆç‚¹è¾ƒå¤šï¼Œå»ºè®®é‡ç‚¹å…³æ³¨æ¥å£æµ‹è¯•å’Œæ•°æ®ä¸€è‡´æ€§")
    
    return recommendations

@app.route('/ai_config')
def ai_config():
    """AIé…ç½®é¡µé¢"""
    return render_template('ai_config.html')

@app.route('/save_ai_config', methods=['POST'])
def save_ai_config():
    """ä¿å­˜AIé…ç½®"""
    try:
        ai_provider = AIProvider(request.form.get('ai_provider'))
        api_key = request.form.get('api_key', '').strip()
        base_url = request.form.get('base_url', '').strip() or None
        model = request.form.get('model', '').strip() or None
        max_tokens = int(request.form.get('max_tokens', 4000))
        temperature = float(request.form.get('temperature', 0.7))
        timeout = int(request.form.get('timeout', 30))

        if not api_key:
            flash('APIå¯†é’¥ä¸èƒ½ä¸ºç©º', 'error')
            return redirect(url_for('ai_config'))

        ai_config = AIConfig(
            provider=ai_provider,
            api_key=api_key,
            base_url=base_url,
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            timeout=timeout
        )

        if config_manager.save_config(ai_config):
            flash('AIé…ç½®ä¿å­˜æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨çœŸå®AIå¤§æ¨¡å‹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹', 'success')
        else:
            flash('AIé…ç½®ä¿å­˜å¤±è´¥', 'error')

    except Exception as e:
        flash(f'ä¿å­˜AIé…ç½®æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}', 'error')

    return redirect(url_for('ai_config'))

@app.route('/test_ai_connection', methods=['POST'])
def test_ai_connection():
    """æµ‹è¯•AIè¿æ¥"""
    try:
        ai_provider = AIProvider(request.form.get('ai_provider'))
        api_key = request.form.get('api_key', '').strip()
        base_url = request.form.get('base_url', '').strip() or None
        model = request.form.get('model', '').strip() or None
        max_tokens = int(request.form.get('max_tokens', 4000))
        temperature = float(request.form.get('temperature', 0.7))
        timeout = int(request.form.get('timeout', 30))

        if not api_key:
            return jsonify({'success': False, 'error': 'APIå¯†é’¥ä¸èƒ½ä¸ºç©º'})

        ai_config = AIConfig(
            provider=ai_provider,
            api_key=api_key,
            base_url=base_url,
            model=model,
            max_tokens=max_tokens,
            temperature=temperature,
            timeout=timeout
        )

        # åˆ›å»ºæµ‹è¯•ç”Ÿæˆå™¨
        test_generator = RealAITestCaseGenerator(ai_config)

        # æµ‹è¯•è¿æ¥
        start_time = time.time()
        test_prompt = "è¯·å›å¤'AIè¿æ¥æµ‹è¯•æˆåŠŸ'æ¥ç¡®è®¤è¿æ¥æ­£å¸¸ã€‚"
        response = test_generator.call_ai_api(test_prompt)
        response_time = int((time.time() - start_time) * 1000)

        return jsonify({
            'success': True,
            'response_time': response_time,
            'model': model or 'default',
            'response': response[:100] + '...' if len(response) > 100 else response
        })

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_ai_status')
def get_ai_status():
    """è·å–AIçŠ¶æ€"""
    status = config_manager.get_config_status()
    return jsonify(status)

@app.route('/delete_ai_config', methods=['POST'])
def delete_ai_config():
    """åˆ é™¤AIé…ç½®"""
    try:
        if config_manager.delete_config():
            return jsonify({'success': True, 'message': 'AIé…ç½®åˆ é™¤æˆåŠŸ'})
        else:
            return jsonify({'success': False, 'error': 'åˆ é™¤å¤±è´¥'})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5001)
